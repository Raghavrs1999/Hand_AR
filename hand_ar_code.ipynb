{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3474df75-6f94-4c99-8600-5840760efe3a",
   "metadata": {},
   "source": [
    "Live camera code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43fb6d0-ec17-4f16-b041-8b419fa13723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def image_on_hand(extracted_region):\n",
    "\n",
    "    mp_hands = mp.solutions.hands\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    cap = cv2.VideoCapture(0)  \n",
    "    #up_img = cv2.resize(extracted_region, (0, 0), fx=0.5, fy=0.5)\n",
    "    up_img = cv2.resize(extracted_region, (30, 30))\n",
    "    with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                continue\n",
    "            \n",
    "            frame = cv2.flip(frame, 1)\n",
    "            \n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            results = hands.process(rgb_frame)\n",
    "            \n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    num_landmarks = len(hand_landmarks.landmark)\n",
    "                    if num_landmarks > 12:  \n",
    "                        index_finger_mcp = hand_landmarks.landmark[13] \n",
    "                        \n",
    "                        frame_height, frame_width, _ = frame.shape\n",
    "    \n",
    "                        x_pixel = int(index_finger_mcp.x * frame_width)\n",
    "                        y_pixel = int(index_finger_mcp.y * frame_height)\n",
    "    \n",
    "                        #print(\"X:\", x_pixel, \"Y:\", y_pixel)\n",
    "                        h1, w1 = up_img.shape[:2]\n",
    "\n",
    "                        if x_pixel + w1 <= frame_width and y_pixel + h1 <= frame_height:\n",
    "                            frame[y_pixel:y_pixel+h1, x_pixel:x_pixel+w1] = up_img\n",
    "                    #mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "    \n",
    "            \n",
    "            cv2.imshow('Hand Tracking', frame)\n",
    "            \n",
    "            key = cv2.waitKey(1)\n",
    "    \n",
    "            if key == 27 or key == ord(\"q\"):\n",
    "                return\n",
    "                \n",
    "\n",
    "def select_object(event, x, y, flags, param):\n",
    "    #print(\"object selection function called\")\n",
    "    global selected_index\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        for idx, (box, mask) in enumerate(zip(boxes, masks)):\n",
    "            r = box.xyxy[0].astype(int)\n",
    "            seg = mask.xy\n",
    "            seg = np.array(seg, dtype=np.int32)\n",
    "            seg = seg.reshape((-1, 1, 2))\n",
    "\n",
    "            if cv2.pointPolygonTest(seg, (x, y), False) >= 0:\n",
    "                selected_index = idx\n",
    "                break\n",
    "\n",
    "selected_index = -1\n",
    "\n",
    "model = YOLO(\"yolov8m-seg.pt\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read() \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    img = cv2.resize(img, (750, 750))\n",
    "    results = model.predict(source=img)\n",
    "    boxes = []\n",
    "    masks = []\n",
    "\n",
    "    for result in results:\n",
    "        boxes.extend(result.boxes.cpu().numpy())\n",
    "        masks.extend(result.masks)\n",
    "    \n",
    "    # Set up the mouse callback for object selection\n",
    "    cv2.namedWindow(\"image\")\n",
    "    cv2.setMouseCallback(\"image\", select_object)\n",
    "\n",
    "    if selected_index != -1 and selected_index < len(boxes):\n",
    "        display_img = img.copy()\n",
    "        box = boxes[selected_index].xyxy[0].astype(int)\n",
    "        mask = masks[selected_index]\n",
    "        seg = mask.xy\n",
    "        seg = np.array(seg, dtype=np.int32)\n",
    "        seg = seg.reshape((-1, 1, 2))\n",
    "        cv2.rectangle(display_img, box[:2], box[2:], (0, 255, 0), 1)\n",
    "        cv2.polylines(display_img, [seg], True, (0, 0, 255), 1)\n",
    "            \n",
    "        object_mask = np.zeros_like(img)\n",
    "        cv2.fillPoly(object_mask, [seg], (255, 255, 255))\n",
    "        object_img = cv2.bitwise_and(img, object_mask)\n",
    "\n",
    "        blank_img = np.zeros_like(object_img)\n",
    "\n",
    "        blank_img = object_img.copy()\n",
    "\n",
    "        results_blank = model.predict(source=blank_img)\n",
    "        boxes_blank = []\n",
    "\n",
    "        for result in results_blank:\n",
    "            boxes_blank.extend(result.boxes.cpu().numpy())\n",
    "\n",
    "        for box in boxes_blank: \n",
    "            r = box.xyxy[0].astype(int)\n",
    "            #print(r)\n",
    "            blank_img = cv2.rectangle(blank_img, r[:2], r[2:], (0, 255, 0), 2)\n",
    "        #cv2.imshow(\"Segmented Object\", blank_img)\n",
    "        #print(blank_img.shape)\n",
    "\n",
    "        box_coordinates = boxes[selected_index].xyxy[0]\n",
    "        x1, y1, x2, y2 = map(int, box_coordinates)\n",
    "        extracted_region = blank_img[y1:y2, x1:x2]\n",
    "        cv2.imshow(\"Extracted Region\", extracted_region)\n",
    "\n",
    "\n",
    "    else:\n",
    "        display_img = img.copy()\n",
    "\n",
    "    cv2.imshow(\"image\", display_img)\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    if key == 13: # it is enter keyboard key \n",
    "        break\n",
    "\n",
    "    # If window is closed, reopen it and reattach the mouse callback\n",
    "    if cv2.getWindowProperty(\"image\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "        cv2.namedWindow(\"image\")\n",
    "        cv2.setMouseCallback(\"image\", select_object)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "image_on_hand(extracted_region)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76f6513-3b5b-42dd-96a4-7a36192f449c",
   "metadata": {},
   "source": [
    "Directory Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac53b42-df2d-4f0c-8e0d-cc7db1ed069a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def image_on_hand(extracted_region):\n",
    "\n",
    "    mp_hands = mp.solutions.hands\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    cap = cv2.VideoCapture(0)  \n",
    "    #up_img = cv2.resize(extracted_region, (0, 0), fx=0.2, fy=0.2)\n",
    "    up_img = cv2.resize(extracted_region, (30, 30))\n",
    "    with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                continue\n",
    "            \n",
    "            frame = cv2.flip(frame, 1)\n",
    "            \n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            results = hands.process(rgb_frame)\n",
    "            \n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    num_landmarks = len(hand_landmarks.landmark)\n",
    "                    if num_landmarks > 5:  \n",
    "                        index_finger_mcp = hand_landmarks.landmark[9] \n",
    "                        \n",
    "                        frame_height, frame_width, _ = frame.shape\n",
    "    \n",
    "                        x_pixel = int(index_finger_mcp.x * frame_width)\n",
    "                        y_pixel = int(index_finger_mcp.y * frame_height)\n",
    "    \n",
    "                        #print(\"X:\", x_pixel, \"Y:\", y_pixel)\n",
    "                        h1, w1 = up_img.shape[:2]\n",
    "\n",
    "                        if x_pixel + w1 <= frame_width and y_pixel + h1 <= frame_height:\n",
    "                            frame[y_pixel:y_pixel+h1, x_pixel:x_pixel+w1] = up_img\n",
    "                    #mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "    \n",
    "            \n",
    "            cv2.imshow('Hand Tracking', frame)\n",
    "            \n",
    "            key = cv2.waitKey(1)\n",
    "    \n",
    "            if key == 27 or key == ord(\"q\"):\n",
    "                break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def select_object(event, x, y, flags, param):\n",
    "    #print(\"object selection function called\")\n",
    "    global selected_index\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        for idx, (box, mask) in enumerate(zip(boxes, masks)):\n",
    "            r = box.xyxy[0].astype(int)\n",
    "            seg = mask.xy\n",
    "            seg = np.array(seg, dtype=np.int32)\n",
    "            seg = seg.reshape((-1, 1, 2))\n",
    "\n",
    "            if cv2.pointPolygonTest(seg, (x, y), False) >= 0:\n",
    "                selected_index = idx\n",
    "                break\n",
    "\n",
    "selected_index = -1\n",
    "\n",
    "model = YOLO(\"yolov8m-seg.pt\")\n",
    "src = \"test.jpeg\"\n",
    "img = cv2.imread(src)\n",
    "img = cv2.resize(img, (750, 750))\n",
    "results = model.predict(source=img)\n",
    "\n",
    "boxes = []\n",
    "masks = []\n",
    "\n",
    "for result in results:\n",
    "    #print(\"prediction is going on\")\n",
    "    boxes.extend(result.boxes.cpu().numpy())\n",
    "    masks.extend(result.masks)\n",
    "\n",
    "cv2.namedWindow(\"image\")\n",
    "cv2.setMouseCallback(\"image\", select_object)\n",
    "\n",
    "while True:\n",
    "    #print(\"showing object\")\n",
    "    if selected_index != -1:\n",
    "        #print(\"object is selected\")\n",
    "        display_img = img.copy()\n",
    "        box = boxes[selected_index].xyxy[0].astype(int)\n",
    "        mask = masks[selected_index]\n",
    "        seg = mask.xy\n",
    "        seg = np.array(seg, dtype=np.int32)\n",
    "        seg = seg.reshape((-1, 1, 2))\n",
    "        cv2.rectangle(display_img, box[:2], box[2:], (0, 255, 0), 1)\n",
    "        cv2.polylines(display_img, [seg], True, (0, 0, 255), 1)\n",
    "        \n",
    "        object_mask = np.zeros_like(img)\n",
    "        cv2.fillPoly(object_mask, [seg], (255, 255, 255))\n",
    "        object_img = cv2.bitwise_and(img, object_mask)\n",
    "\n",
    "        blank_img = np.zeros_like(object_img)\n",
    "\n",
    "        blank_img = object_img.copy()\n",
    "\n",
    "        results_blank = model.predict(source=blank_img)\n",
    "        boxes_blank = []\n",
    "\n",
    "        for result in results_blank:\n",
    "            boxes_blank.extend(result.boxes.cpu().numpy())\n",
    "\n",
    "        for box in boxes_blank: \n",
    "            r = box.xyxy[0].astype(int)\n",
    "            #print(r)\n",
    "            blank_img = cv2.rectangle(blank_img, r[:2], r[2:], (0, 255, 0), 2)\n",
    "        #cv2.imshow(\"Segmented Object\", blank_img)\n",
    "        #print(blank_img.shape)\n",
    "\n",
    "        x1, y1, x2, y2 = box.xyxy[0].astype(int)\n",
    "        extracted_region = blank_img[y1:y2, x1:x2]\n",
    "        cv2.imshow(\"Extracted Region\", extracted_region)\n",
    "\n",
    "\n",
    "    else:\n",
    "        display_img = img.copy()\n",
    "\n",
    "    cv2.imshow(\"image\", display_img)\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    if key == 13: # it is enter keyboard key \n",
    "        break\n",
    "\n",
    "    # If window is closed, reopen it and reattach the mouse callback\n",
    "    if cv2.getWindowProperty(\"image\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "        cv2.namedWindow(\"image\")\n",
    "        cv2.setMouseCallback(\"image\", select_object)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "image_on_hand(extracted_region)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc53264-b4cd-4041-baf9-e72e8228d118",
   "metadata": {},
   "source": [
    "                                                                    THANK YOU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
